# å¿«é€Ÿå¼€å§‹

## 5åˆ†é’Ÿå¿«é€Ÿå…¥é—¨

### å®‰è£…ä¾èµ–

```bash
pip install transformers torch
```

### æœ€å°ç¤ºä¾‹

```python
from llmrankers.universal_setwise import UniversalSetwiseLlmRanker
from llmrankers.universal_ranker import SearchResult

# 1ï¸âƒ£ åˆå§‹åŒ–rankerï¼ˆä»»ä½•HuggingFaceæ¨¡å‹ï¼ï¼‰
ranker = UniversalSetwiseLlmRanker("google/flan-t5-base", device='cuda')

# 2ï¸âƒ£ å‡†å¤‡å¾…æ’åºæ–‡æ¡£
docs = [
    SearchResult("1", 10, "Machine learning is a subset of AI"),
    SearchResult("2", 9, "Deep learning uses neural networks"),
    SearchResult("3", 8, "NLP processes natural language"),
    SearchResult("4", 7, "Computer vision processes images"),
    SearchResult("5", 6, "Reinforcement learning uses rewards"),
]

# 3ï¸âƒ£ æ‰§è¡Œé‡æ’åº
query = "machine learning techniques"
results = ranker.rerank(query, docs)

# 4ï¸âƒ£ æŸ¥çœ‹ç»“æœ
for i, doc in enumerate(results[:3]):
    print(f"{i+1}. Doc {doc.docid} (score: {doc.score})")
```

**è¾“å‡º:**
```
1. Doc 1 (score: -1)
2. Doc 2 (score: -2)
3. Doc 3 (score: -3)
```

---

## ä¸ä¸åŒæ¨¡å‹é›†æˆ

### ä½¿ç”¨T5

```python
ranker = UniversalSetwiseLlmRanker("google/flan-t5-large", k=10)
results = ranker.rerank(query, docs)
```

### ä½¿ç”¨LLaMA

```python
ranker = UniversalSetwiseLlmRanker("meta-llama/Llama-2-7b-chat-hf")
results = ranker.rerank(query, docs)
```

### ä½¿ç”¨Mistral

```python
ranker = UniversalSetwiseLlmRanker("mistralai/Mistral-7B-Instruct-v0.1")
results = ranker.rerank(query, docs)
```

### ä½¿ç”¨ä»»ä½•å…¶ä»–æ¨¡å‹

```python
ranker = UniversalSetwiseLlmRanker("your-hf-model-name")
results = ranker.rerank(query, docs)
```

---

## å¸¸è§é…ç½®

### å¿«é€Ÿæ¨¡å¼ï¼ˆä½å»¶è¿Ÿï¼‰
```python
ranker = UniversalSetwiseLlmRanker(
    model_name_or_path="google/flan-t5-base",
    k=5,
    num_child=2,  # å‡å°‘æ¯”è¾ƒ
    device='cuda'
)
```

### å¹³è¡¡æ¨¡å¼ï¼ˆæ¨èï¼‰
```python
ranker = UniversalSetwiseLlmRanker(
    model_name_or_path="google/flan-t5-large",
    k=10,
    num_child=3,  # æ ‡å‡†å€¼
    method="heapsort",
    device='cuda'
)
```

### é«˜ç²¾åº¦æ¨¡å¼ï¼ˆéœ€è¦æŠ•ç¥¨ï¼‰
```python
from llmrankers.universal_setwise import UniversalSetwiseLlmRankerWithVoting

ranker = UniversalSetwiseLlmRankerWithVoting(
    model_name_or_path="meta-llama/Llama-2-13b-chat-hf",
    k=10,
    num_child=4,
    num_permutation=3,  # ä»3ä¸ªæ’åˆ—æŠ•ç¥¨
    device='cuda'
)
```

---

## æ‰¹é‡å¤„ç†

```python
queries = [
    "machine learning",
    "deep learning",
    "natural language processing"
]

for query in queries:
    results = ranker.rerank(query, docs)
    print(f"\n{query}:")
    for doc in results[:3]:
        print(f"  - Doc {doc.docid}")
```

---

## è‡ªå®šä¹‰æç¤ºè¯

```python
class CustomRanker(UniversalSetwiseLlmRanker):
    def compare(self, query, docs):
        passages = "\n".join([f"[{self.CHARACTERS[i]}] {doc.text}" 
                             for i, doc in enumerate(docs)])
        
        prompt = f"""
Query: {query}

Passages:
{passages}

Which passage is most relevant? (Answer: A, B, C, ...)
"""
        output = self.adapter.generate([prompt], max_new_tokens=2)[0]
        return output[0].upper()

ranker = CustomRanker("google/flan-t5-base")
results = ranker.rerank(query, docs)
```

---

## æ•…éšœæ’é™¤

### GPUå†…å­˜ä¸è¶³ï¼Ÿ

```bash
# ä½¿ç”¨CPU
ranker = UniversalSetwiseLlmRanker("model", device='cpu')

# æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ranker = UniversalSetwiseLlmRanker("google/flan-t5-base")  # å°æ¨¡å‹

# æˆ–é‡åŒ–
ranker = UniversalSetwiseLlmRanker("model")  # ä¼šè‡ªåŠ¨ä½¿ç”¨8-bit
```

### æ¨¡å‹ä¸‹è½½ç¼“æ…¢ï¼Ÿ

```python
# ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
ranker = UniversalSetwiseLlmRanker("/path/to/local/model")
```

### HuggingFace Hubæƒé™é”™è¯¯ï¼Ÿ

```bash
# ç™»å½•HuggingFace
huggingface-cli login

# æˆ–è®¾ç½®token
huggingface-cli login --token <your-token>
```

---

## æ€§èƒ½æç¤º

| æ“ä½œ | ä¼˜åŒ–æ–¹æ¡ˆ |
|------|--------|
| é™ä½å»¶è¿Ÿ | ä½¿ç”¨smaller modelï¼ˆflan-t5-baseï¼‰ + k=5 + num_child=2 |
| æé«˜ç²¾åº¦ | ä½¿ç”¨larger model + num_permutation=3 |
| èŠ‚çœå†…å­˜ | ä½¿ç”¨T5-baseè€Œä¸æ˜¯LLaMA-7b |
| å¿«é€Ÿå®éªŒ | CPUæ¨ç†ç”¨æ¥æµ‹è¯•ï¼Œç¡®è®¤åç”¨GPU |

---

## ä¸ç°æœ‰ä»£ç é›†æˆ

### æ–¹å¼1ï¼šç›´æ¥æ›¿æ¢ï¼ˆæ¨èï¼‰

```python
# æ—§ä»£ç 
# from llmrankers.setwise import SetwiseLlmRanker

# æ–°ä»£ç 
from llmrankers.universal_setwise import UniversalSetwiseLlmRanker as SetwiseLlmRanker

# å…¶ä»–ä»£ç å®Œå…¨ä¸å˜ï¼
ranker = SetwiseLlmRanker(model_path)
results = ranker.rerank(query, ranking)
```

### æ–¹å¼2ï¼šå¹¶è¡Œä½¿ç”¨

```python
from llmrankers.setwise import SetwiseLlmRanker  # æ—§çš„
from llmrankers.universal_setwise import UniversalSetwiseLlmRanker  # æ–°çš„

# æ—§é¡¹ç›®ç”¨æ—§ranker
old_ranker = SetwiseLlmRanker("flan-t5-large")

# æ–°é¡¹ç›®ç”¨æ–°ranker
new_ranker = UniversalSetwiseLlmRanker("mistral-7b")
```

### æ–¹å¼3ï¼šæ¸è¿›è¿ç§»

```python
import sys

# å®šä¹‰å“ªäº›æ¨¡å—ä½¿ç”¨æ–°ranker
USE_UNIVERSAL = {'new_module', 'experimental'}

if sys.modules.get('__main__').__name__ in USE_UNIVERSAL:
    from llmrankers.universal_setwise import UniversalSetwiseLlmRanker as SetwiseLlmRanker
else:
    from llmrankers.setwise import SetwiseLlmRanker
```

---

## æ–‡æ¡£å¯¼èˆª

| æ–‡æ¡£ | å†…å®¹ |
|------|------|
| `SOLUTION_SUMMARY.md` | æ•´ä½“è§£å†³æ–¹æ¡ˆæ€»ç»“ |
| `ARCHITECTURE.md` | è¯¦ç»†æ¶æ„è®¾è®¡ |
| `ARCHITECTURE_DIAGRAM.md` | å¯è§†åŒ–æ¶æ„ |
| `MIGRATION_GUIDE.md` | è¿ç§»æŒ‡å— |
| `MODEL_REFERENCE.md` | æ¨¡å‹å‚è€ƒè¡¨ |
| `example_universal_ranker.py` | 7ä¸ªå®Œæ•´ç¤ºä¾‹ |

---

## ä¸‹ä¸€æ­¥

1. âœ… é˜…è¯»æœ¬æ–‡æ¡£ï¼ˆå·²å®Œæˆï¼‰
2. â³ å°è¯•æœ€å°ç¤ºä¾‹
3. â³ ç”¨ä½ è‡ªå·±çš„æ•°æ®æµ‹è¯•
4. â³ é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹
5. â³ é›†æˆåˆ°ä½ çš„é¡¹ç›®

---

## è·å–å¸®åŠ©

**å¸¸è§é—®é¢˜ï¼š**
- æ”¯æŒå“ªäº›æ¨¡å‹ï¼Ÿâ†’ æŸ¥çœ‹ `MODEL_REFERENCE.md`
- å¦‚ä½•è‡ªå®šä¹‰ï¼Ÿ â†’ æŸ¥çœ‹ `example_universal_ranker.py`
- å¦‚ä½•è¿ç§»ç°æœ‰ä»£ç ï¼Ÿ â†’ æŸ¥çœ‹ `MIGRATION_GUIDE.md`
- æ¶æ„æ˜¯ä»€ä¹ˆï¼Ÿ â†’ æŸ¥çœ‹ `ARCHITECTURE_DIAGRAM.md`

---

**å¼€å§‹ä½¿ç”¨å§ï¼ğŸš€**

```python
from llmrankers.universal_setwise import UniversalSetwiseLlmRanker

# é€‰æ‹©ä½ å–œæ¬¢çš„æ¨¡å‹
ranker = UniversalSetwiseLlmRanker("your-model-here")

# å®Œæˆï¼
results = ranker.rerank(query, docs)
```
